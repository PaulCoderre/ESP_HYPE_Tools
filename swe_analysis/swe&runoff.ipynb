{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e209587-5928-4cb5-9e1a-9b775ca2d0d6",
   "metadata": {},
   "source": [
    "## Description\n",
    "____\n",
    "This script generates plots comparing the amount of SWE on a given date with the amount of summer  \n",
    "streamflow between two given dates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f170c186-0012-489e-80aa-f6bc53d61d73",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9578b684-4c89-4ca7-ad5c-d88582830eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee36c77-b036-4a33-81f9-9dad5842b03c",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c95c4a-2161-4ee9-9619-ec61e17dfdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Easymore SWE directory path\n",
    "directory= 'easymore_snotel/'\n",
    "\n",
    "# Define the start month and day of analysis\n",
    "month = 4\n",
    "day = 1\n",
    "\n",
    "# define end month and day of analysis\n",
    "end_month= 6\n",
    "end_day= 30\n",
    "\n",
    "# Path to HYPE observed flow \n",
    "qobs= '../esp_hype/model/Qobs.txt'\n",
    "\n",
    "# HYPE river segment to be analyzed\n",
    "riv_seg= '58213'\n",
    "\n",
    "# Output image location\n",
    "output_dir = './plots/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba9a71e-2f5c-4b14-aa78-5dad23393ec7",
   "metadata": {},
   "source": [
    "### Get Upstream Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308b6b99-1f8b-49d9-b980-afd0f74587df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the river and catchment shapefiles\n",
    "gdf = gpd.read_file('smm_tgf_modified/smm_riv.shp')\n",
    "catchment= gpd.read_file('smm_tgf_modified/smm_cat.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05212a75-d002-4270-b686-1c868372ac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary from 'hru_nhm' and 'seg_nhm' columns in catchment\n",
    "segment_dict = dict(zip(catchment['seg_nhm'], catchment['hru_nhm']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5441faf7-78f2-410f-9024-74189d56d143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to string data type\n",
    "gdf['seg_nhm'] = gdf['seg_nhm'].astype(str)\n",
    "gdf['ds_seg_nhm'] = gdf['ds_seg_nhm'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dce6819-59cb-4570-be0d-1dc1ebbf93c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directed graph\n",
    "riv_graph = nx.DiGraph()\n",
    "\n",
    "# Add edges from DataFrame\n",
    "for idx, row in gdf.iterrows():\n",
    "    if row['ds_seg_nhm'] != '0':  # Skip if ds_seg_nhm is '0'\n",
    "        riv_graph.add_edge(row['seg_nhm'], row['ds_seg_nhm'])\n",
    "\n",
    "# Find upstream segments for given segment\n",
    "upstream_segments = list(nx.ancestors(riv_graph, riv_seg))\n",
    "\n",
    "# Add the target segment 'riv_seg' to the upstream segments\n",
    "upstream_segments.append(riv_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472ec24c-f139-46c6-a7db-f031c62e08cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert keys in segment_dict to integers\n",
    "segment_dict = {int(k): v for k, v in segment_dict.items()}\n",
    "\n",
    "# Convert values in upstream_segments to integers\n",
    "upstream_segments = [int(seg) for seg in upstream_segments]\n",
    "\n",
    "# Convert stream segments to hru IDs for comparison with snotel\n",
    "upstream_segments = [segment_dict.get(seg, seg) for seg in upstream_segments]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0732b8bc-50bd-47a5-9dab-9f868c995112",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SWE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5612cbf2-88bf-4be0-9083-47022cff0c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store results\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8b55e5-81ca-4f2b-b63b-fa81cf70b91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each .nc file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.nc'):\n",
    "        # Read the dataset into xarray\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        dataset = xr.open_dataset(filepath)\n",
    "        \n",
    "        # List to store total SWE for each upstream segment\n",
    "        total_swe_list = []\n",
    "        \n",
    "        for seg in upstream_segments:            \n",
    "            # Select the 'swe' variable and subset by ID\n",
    "            subset_data = dataset['swe'].sel(ID=seg)\n",
    "\n",
    "            # Convert the xarray DataArray to a pandas DataFrame\n",
    "            df = subset_data.to_dataframe().reset_index()\n",
    "\n",
    "            # Convert 'time' column to datetime format\n",
    "            df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "            # Set 'time' column as index and drop 'ID' column\n",
    "            df.set_index('time', inplace=True)\n",
    "            df.drop(columns=['ID'], inplace=True)\n",
    "\n",
    "            # Convert the index to datetime format if it's not already\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "            \n",
    "            # Create a mask for the specified month and day\n",
    "            mask = (df.index.month == month) & (df.index.day == day)\n",
    "\n",
    "            # Apply the mask to filter the DataFrame\n",
    "            filtered_df = df.loc[mask]\n",
    "\n",
    "            # Extract the 'SWE' value\n",
    "            swe_value = filtered_df['swe'].values[0] if not filtered_df.empty else None\n",
    "\n",
    "            # For total winter SWE\n",
    "            # Create a mask for the specified month and day\n",
    "            # mask = (df.index.month < month) | ((df.index.month == month) & (df.index.day <= day))\n",
    "\n",
    "            # Apply the mask to filter the DataFrame\n",
    "            #filtered_df = df.loc[mask]\n",
    "\n",
    "            # Sum the 'SWE' values\n",
    "           #total_swe = filtered_df['swe'].sum()\n",
    "            \n",
    "            # Append the total SWE to the list\n",
    "            total_swe_list.append(swe_value)\n",
    "        \n",
    "        # Get the first date in the filtered DataFrame\n",
    "        first_date = filtered_df.index.min()\n",
    " \n",
    "        \n",
    "        # Append the results to the final list\n",
    "        results.append([filename, sum(total_swe_list), first_date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfa0c27-1a20-4510-9dd3-4812603ad240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to a DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results, columns=['Filename', 'Total_SWE', 'First_Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d335ff7-b27d-4b69-800d-bde68b0c2234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column 'Rank' to rank the 'Total_SWE' values from largest to smallest\n",
    "results_df['SWE_Rank'] = results_df['Total_SWE'].rank(ascending=False).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95817153-7ed7-40dc-99c3-b57419567967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'First_Date' column to only include the year\n",
    "results_df['First_Date'] = results_df['First_Date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1608eeee-ad56-4918-8e17-e0a38d239a98",
   "metadata": {},
   "source": [
    "### Qobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd090e06-a78e-4d05-bb7a-a6909fbd047a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read qobs hype input to dataframe\n",
    "df = pd.read_csv(qobs, sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4323840-e507-472e-ba72-4059d8d8ff76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the index to datetime\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "# Change the headers to integers\n",
    "df.columns = df.columns.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d4024d-cdb2-4161-a0cd-e58c4e0126bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all columns that are not equal to 'riv_seg'\n",
    "df = df.loc[:, df.columns == int(riv_seg)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc2947b-84e5-4a6e-aff6-ba34989c6c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame to store the results\n",
    "qobs_df = pd.DataFrame(columns=['Year', 'Total_flow'])\n",
    "\n",
    "# Iterate over unique years in the index\n",
    "for year in df.index.year.unique():\n",
    "    # Define start and end dates for filtering\n",
    "    start_date = f\"{year}-{month}-{day}\"\n",
    "    end_date = f\"{year}-{end_month}-{end_day}\"\n",
    "    \n",
    "    # Create a mask for the specified date range\n",
    "    mask = (df.index >= start_date) & (df.index <= end_date)\n",
    "    \n",
    "    # Apply the mask to filter the DataFrame\n",
    "    filtered_df = df.loc[mask]\n",
    "    \n",
    "    # Sum the summer streamflow values\n",
    "    total_swe = filtered_df[int(riv_seg)].sum()\n",
    "    \n",
    "    # Append the results to the results DataFrame\n",
    "    qobs_df = pd.concat([qobs_df, pd.DataFrame({'Year': [year], 'Total_flow': [total_swe]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7025e6f0-3f7d-4e61-a6c4-65a1a900be20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank the 'Total_flow' values from largest to smallest\n",
    "qobs_df['Flow_Rank'] = qobs_df['Total_flow'].rank(ascending=False).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff45151-e42c-49de-9d2e-61096aefa59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge results_df and qobs_df based on 'First_Date' and 'Year' columns\n",
    "merged_df = pd.merge(results_df, qobs_df, left_on='First_Date', right_on='Year', how='inner')\n",
    "\n",
    "# Drop the duplicate 'Year' column\n",
    "merged_df.drop(columns=['Year'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19f9ee0-44b7-4ec3-bd5b-23e7925746db",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2153db-f266-4a05-8b34-30eeb398f085",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39ffd99-c7ac-40f0-90af-c4db04d20f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(merged_df['Flow_Rank'], merged_df['SWE_Rank'], label='SWE vs Flow Rank', color='blue')\n",
    "\n",
    "# Compute regression line\n",
    "slope, intercept, r_value, p_value, std_err = linregress(merged_df['Flow_Rank'], merged_df['SWE_Rank'])\n",
    "regression_line = slope * merged_df['Flow_Rank'] + intercept\n",
    "\n",
    "# Plot regression line with thinner and dashed style\n",
    "plt.plot(merged_df['Flow_Rank'], regression_line, color='red',  linewidth=0.7, label=f'Regression Line\\nR-squared: {r_value**2:.2f}')\n",
    "\n",
    "# Set plot title and labels\n",
    "plt.title(f'April 1st SWE and Summer Runoff at Segment {riv_seg}')\n",
    "plt.xlabel('Flow Rank')\n",
    "plt.ylabel('SWE Rank')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the plot as an image file\n",
    "output_file_path = os.path.join(output_dir, f'{riv_seg}_SWEvsFlow')\n",
    "plt.savefig(output_file_path, dpi=300)  # dpi specifies the resolution (dots per inch)\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print R-squared value\n",
    "print(f'R-squared: {r_value**2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d13481-51a0-49ea-8165-9ea0c2a61169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6edeff-14d1-446a-a7fa-00b14285771a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
