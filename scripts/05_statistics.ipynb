{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35d139ef-270e-4d92-9a46-036cfb163bfb",
   "metadata": {},
   "source": [
    "## Description\n",
    "_______\n",
    "\n",
    "This script calculates statistics for the simulated vs. observed streamflow from the ESP outputs. \n",
    "Statistics currently being calculated are bias for each year included in the ESP analysis, correlation coefficient,\n",
    "RMSE and NSE (Huang et al. 2017). These statistics are being calculated with the mean of the ensemble. \n",
    "The variables used for the calculations are described in the \"Other Stitistics\" cell so that additional stats can easily be added. Stats are calculated between start_date and end_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516a2092-0036-482a-9828-7dad5224593e",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01abbe77-9fb8-4d20-adda-3bc7b5e62816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.integrate import simps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2c2823-9507-493b-b26a-e066b83b6858",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74789fc1-c98d-408e-b683-cb04ed23fc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define inputs for the plot\n",
    "directory_path= '../58213_esp_results/' # directory containing ESP outputs\n",
    "start_date= '04-01'       # start date for esp analysis in %Y-%m-%d\n",
    "end_date= '04-30'         # end date for esp analysis in %Y-%m-%d\n",
    "output_directory= '../'   # location for the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4ed2b7a-d10a-4cd2-8396-df03455b3fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding computed runoff for given year (optional, replace with False if not using)\n",
    "computed_path= None #'../0058213.txt'\n",
    "swe_rank= '../swe_analysis/swerank.csv' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486a55e1-0924-4e18-9565-51631a333d50",
   "metadata": {},
   "source": [
    "### Generate Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4434a601-9d8e-472e-ab63-8882f562353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract month and day from the dates\n",
    "start_month, start_day = start_date.split('-')\n",
    "end_month, end_day = end_date.split('-')\n",
    "\n",
    "# Convert dates to integers\n",
    "start_month, start_day = int(start_month), int(start_day)\n",
    "end_month, end_day = int(end_month), int(end_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfdc2779-5476-43ed-b75a-4e32c2937872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the total simulated runoff for each ensemble member\n",
    "all_sum_cout_series = []\n",
    "\n",
    "# Initialize an empty list to store the total observed runoff for each ensemble member\n",
    "all_sum_rout_series = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5956c90-1a03-412c-a27d-d1602ce800d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if computed_path is not None:\n",
    "    # Read the DataFrame from the computed_path\n",
    "    sim = pd.read_csv(computed_path, sep='\\t', index_col=0)\n",
    "\n",
    "    sim = sim.drop('UNITS', axis=0)\n",
    "\n",
    "    # Convert index to datetime format\n",
    "    sim.index = pd.to_datetime(sim.index, errors='coerce')\n",
    "\n",
    "    # Convert 'cout' column to numeric if needed\n",
    "    sim['cout'] = pd.to_numeric(sim['cout'], errors='coerce')\n",
    "    \n",
    "    # Extract unique years from the index of sim\n",
    "    unique_years = sim.index.year.unique()\n",
    "\n",
    "    # Initialize an empty list to store trimmed DataFrames\n",
    "    trimmed_dfs = []\n",
    "\n",
    "    # Loop through each unique year\n",
    "    for year in unique_years:\n",
    "        # Trim the DataFrame to keep only data within the specified start and end dates for each year\n",
    "        year_start_date = '{}-{}'.format(year, start_date)\n",
    "        year_end_date = '{}-{}'.format(year, end_date)\n",
    "        trimmed_df = sim.loc[year_start_date:year_end_date]\n",
    "        trimmed_dfs.append(trimmed_df)\n",
    "\n",
    "    # Concatenate the trimmed DataFrames into a single DataFrame\n",
    "    sim_trimmed = pd.concat(trimmed_dfs)\n",
    "\n",
    "    # Drop all columns except for 'cout'\n",
    "    sim_cout = sim_trimmed[['cout']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a6cb1ec-7c56-41b8-bc72-b57a2e1fd6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if computed_path is not None:\n",
    "    # Read the DataFrame from the computed_path\n",
    "    sim = pd.read_csv(computed_path, sep='\\t', index_col=0)\n",
    "\n",
    "    sim = sim.drop('UNITS', axis=0)\n",
    "\n",
    "    # Convert index to datetime format\n",
    "    sim.index = pd.to_datetime(sim.index, errors='coerce')\n",
    "\n",
    "    # Convert 'cout' column to numeric if needed\n",
    "    sim['cout'] = pd.to_numeric(sim['cout'], errors='coerce')\n",
    "    \n",
    "    # Extract unique years from the index of sim\n",
    "    unique_years = sim.index.year.unique()\n",
    "\n",
    "    # Initialize an empty list to store trimmed DataFrames\n",
    "    trimmed_dfs = []\n",
    "\n",
    "    # Loop through each unique year\n",
    "    for year in unique_years:\n",
    "        # Trim the DataFrame to keep only data within the specified start and end dates for each year\n",
    "        year_start_date = '{}-{}'.format(year, start_date)\n",
    "        year_end_date = '{}-{}'.format(year, end_date)\n",
    "        trimmed_df = sim.loc[year_start_date:year_end_date]\n",
    "        trimmed_dfs.append(trimmed_df)\n",
    "\n",
    "    # Concatenate the trimmed DataFrames into a single DataFrame\n",
    "    sim_trimmed = pd.concat(trimmed_dfs)\n",
    "\n",
    "    # Drop all columns except for 'cout'\n",
    "    sim_cout = sim_trimmed[['cout']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e29a4819-611e-4001-b9ae-ade2088b49ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each .nc file in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.nc'):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        \n",
    "        # Open the esp output file\n",
    "        esp = xr.open_dataset(file_path)\n",
    "        \n",
    "        # Convert all data variable values to float\n",
    "        esp = esp.astype(float)\n",
    "        \n",
    "        # Convert 'DATE' coordinate to datetime format\n",
    "        esp['DATE'] = pd.to_datetime(esp['DATE'])\n",
    "        \n",
    "        # Extract the year from the last DATE\n",
    "        last_date_year = pd.to_datetime(esp['DATE'][-1].values).year\n",
    "        \n",
    "        # Create start_date and end_date for the analysis period\n",
    "        start_date = pd.Timestamp(year=last_date_year, month=start_month, day=start_day)\n",
    "        end_date = pd.Timestamp(year=last_date_year, month=end_month, day=end_day)\n",
    "        \n",
    "        # Select data between start_date and end_date \n",
    "        ds_selected = esp.sel(DATE=slice(start_date, end_date))\n",
    "        \n",
    "        # Sum 'cout' variable for each ensemble member\n",
    "        sum_cout = ds_selected['cout'].mean(dim='ensemble_member')\n",
    "        sum_rout= ds_selected['rout'].mean(dim='ensemble_member')\n",
    "        \n",
    "        # Convert sum_cout to pandas Series\n",
    "        sum_cout_series = sum_cout.to_series()\n",
    "        sum_rout_series = sum_rout.to_series()\n",
    "        \n",
    "        # Ensure the simulated index is a DatetimeIndex and add year of analysis to series\n",
    "        sum_cout_series.index = pd.to_datetime(sum_cout_series.index)\n",
    "        sum_cout_series.index = sum_cout_series.index.map(lambda x: x.replace(year=last_date_year))\n",
    "        \n",
    "        # Ensure the observed index is a DatetimeIndex and add year of analysis to series\n",
    "        sum_rout_series.index = pd.to_datetime(sum_rout_series.index)\n",
    "        sum_rout_series.index = sum_rout_series.index.map(lambda x: x.replace(year=last_date_year))\n",
    "        \n",
    "        # Append the simulated and observed series to the list\n",
    "        all_sum_cout_series.append(sum_cout_series)\n",
    "        all_sum_rout_series.append(sum_rout_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab83d936-ac3b-4672-9064-3d65f7d6d4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all sum_cout_series into a single series\n",
    "sum_cout_series_combined = pd.concat(all_sum_cout_series)\n",
    "sum_rout_series_combined = pd.concat(all_sum_rout_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc3fcfa-0e5e-41ba-8209-4d0131878a38",
   "metadata": {},
   "source": [
    "#### Calculate Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8402b75-50e5-4c24-92a5-3c87497925d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results dataframe\n",
    "results = pd.DataFrame({\n",
    "    'ESP Mean Total Flow (cms)': sum_cout_series_combined,\n",
    "    'Observed Total Flow (cms)': sum_rout_series_combined\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1918173-bc69-458a-8860-61672919a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percent bias for each day\n",
    "results['Percent Bias'] = ((results['ESP Mean Total Flow (cms)'] - results['Observed Total Flow (cms)']) / results['Observed Total Flow (cms)']) * 100\n",
    "\n",
    "# Group by year and calculate the mean percent bias for each year\n",
    "mean_percent_bias_by_year = results.groupby(results.index.year)['Percent Bias'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1035e04e-4278-4e43-b302-26abd2412cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame called 'statistics' from the Series with index defined\n",
    "statistics = pd.DataFrame(columns=['Mean Percent Bias'], index=mean_percent_bias_by_year.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71a11d84-cd03-46d3-89ec-0397481e04f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the 'Mean Percent Bias' column with the values from 'mean_percent_bias_by_year'\n",
    "statistics['Mean Percent Bias'] = mean_percent_bias_by_year.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1f01738-a6aa-43bd-988b-25dd54ab1d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store correlation coefficients\n",
    "correlation_coefficients = []\n",
    "\n",
    "# Iterate over unique years in the index\n",
    "for year in results.index.year.unique():\n",
    "    # Filter the data for the current year\n",
    "    year_data = results[results.index.year == year]\n",
    "    # Calculate the correlation coefficient for the current year\n",
    "    correlation_coefficient = np.corrcoef(year_data['ESP Mean Total Flow (cms)'], year_data['Observed Total Flow (cms)'])[0, 1]\n",
    "    # Append the correlation coefficient to the list\n",
    "    correlation_coefficients.append(correlation_coefficient)\n",
    "\n",
    "statistics['Correlation Coefficient'] = correlation_coefficients\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd8c5810-1b3e-4e68-b994-65079e76a0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store RMSE values\n",
    "rmse_values = []\n",
    "\n",
    "# Iterate over unique years in the index\n",
    "for year in results.index.year.unique():\n",
    "    # Filter the data for the current year\n",
    "    year_data = results[results.index.year == year]\n",
    "    # Calculate RMSE for the current year\n",
    "    rmse = np.sqrt(np.mean((year_data['Observed Total Flow (cms)'] - year_data['ESP Mean Total Flow (cms)'])**2))\n",
    "    # Append the RMSE value to the list\n",
    "    rmse_values.append(rmse)\n",
    "\n",
    "# Create a DataFrame called 'statistics' with 'RMSE' for each year\n",
    "statistics['RMSE'] = rmse_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "337c109f-0567-4d99-b8a7-847aa81d6fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store NSE values\n",
    "nse_values = []\n",
    "\n",
    "# Iterate over unique years in the index\n",
    "for year in results.index.year.unique():\n",
    "    # Filter the data for the current year\n",
    "    year_data = results[results.index.year == year]\n",
    "    # Calculate the mean of observed flow for the current year\n",
    "    mean_observed = year_data['Observed Total Flow (cms)'].mean()\n",
    "    # Calculate the numerator of the Nash-Sutcliffe Efficiency (NSE)\n",
    "    numerator = np.sum((year_data['Observed Total Flow (cms)'] - year_data['ESP Mean Total Flow (cms)'])**2)\n",
    "    # Calculate the denominator of the Nash-Sutcliffe Efficiency (NSE)\n",
    "    denominator = np.sum((year_data['Observed Total Flow (cms)'] - mean_observed)**2)\n",
    "    # Calculate NSE for the current year\n",
    "    nse = 1 - (numerator / denominator)\n",
    "    # Append the NSE value to the list\n",
    "    nse_values.append(nse)\n",
    "\n",
    "# Create a DataFrame called 'statistics' with 'NSE' for each year\n",
    "statistics['NSE'] = nse_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346b64aa-7ff3-4bad-b207-c5584d41dc95",
   "metadata": {},
   "source": [
    "SWE Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebe3a0c3-781e-4d5e-8536-57e632be336b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if swe_rank is not None:\n",
    "    # Read CSV into a DataFrame\n",
    "    swe_rank_df = pd.read_csv(swe_rank, index_col=0)\n",
    "    \n",
    "    # Merge 'SWE_Rank' column onto 'statistics' based on indexes\n",
    "    statistics= pd.merge(statistics, swe_rank_df['SWE_Rank'], left_index=True, right_index=True)\n",
    "    \n",
    "    \n",
    "    # Move 'SWE_Rank' column to the first position\n",
    "    statistics.insert(0, 'SWE_Rank', statistics.pop('SWE_Rank'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0434b43f-3933-457d-be9b-a4475b5fee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if computed_path is not None:\n",
    "    \n",
    "    # Extract unique years from the index of sum_cout_series_combined\n",
    "    unique_years_sum = sum_cout_series_combined.index.year.unique()\n",
    "\n",
    "    # Filter sim_cout to include only the years found in sum_cout_series_combined\n",
    "    sim_cout_filtered = sim_cout[sim_cout.index.year.isin(unique_years_sum)].copy()\n",
    "    \n",
    "    # Assign values from sum_cout_series_combined to a new column 'ESP Mean Total Flow (cms)'\n",
    "    sim_cout_filtered.loc[:, 'ESP Mean Total Flow (cms)'] = sum_cout_series_combined.values\n",
    "\n",
    "    # Calculate the percent bias for each day\n",
    "    sim_cout_filtered['Percent Bias'] = ((sim_cout_filtered['ESP Mean Total Flow (cms)'] - sim_cout_filtered['cout']) / sim_cout_filtered['cout']) * 100\n",
    "\n",
    "    # Group by year and calculate the mean percent bias for each year\n",
    "    mean_percent_bias_by_year_cout = sim_cout_filtered.groupby(sim_cout_filtered.index.year)['Percent Bias'].mean()\n",
    "    \n",
    "    # Create a DataFrame called 'statistics' from the Series with index defined\n",
    "    cout_stats = pd.DataFrame(columns=['Mean Percent Bias'], index=mean_percent_bias_by_year.index)\n",
    "    \n",
    "    # Populate the 'Mean Percent Bias' column with the values from 'mean_percent_bias_by_year'\n",
    "    cout_stats['Mean Percent Bias'] = mean_percent_bias_by_year_cout.values\n",
    "    \n",
    "    # Initialize an empty list to store correlation coefficients\n",
    "    correlation_coefficients1 = []\n",
    "\n",
    "    # Iterate over unique years in the index\n",
    "    for year in sim_cout_filtered.index.year.unique():\n",
    "        # Filter the data for the current year\n",
    "        year_data1 = sim_cout_filtered[sim_cout_filtered.index.year == year]\n",
    "        # Calculate the correlation coefficient for the current year\n",
    "        correlation_coefficient1 = np.corrcoef(year_data1['ESP Mean Total Flow (cms)'], year_data1['cout'])[0, 1]\n",
    "        # Append the correlation coefficient to the list\n",
    "        correlation_coefficients1.append(correlation_coefficient1)\n",
    "\n",
    "    cout_stats['Correlation Coefficient'] = correlation_coefficients1\n",
    "    \n",
    "    \n",
    "        # Initialize an empty list to store RMSE values\n",
    "    rmse_values1 = []\n",
    "\n",
    "    # Iterate over unique years in the index\n",
    "    for year in sim_cout_filtered.index.year.unique():\n",
    "        # Filter the data for the current year\n",
    "        year_data = sim_cout_filtered[sim_cout_filtered.index.year == year]\n",
    "        # Calculate RMSE for the current year\n",
    "        rmse1 = np.sqrt(np.mean((year_data['cout'] - year_data['ESP Mean Total Flow (cms)'])**2))\n",
    "        # Append the RMSE value to the list\n",
    "        rmse_values1.append(rmse1)\n",
    "\n",
    "    # Create a DataFrame called 'statistics' with 'RMSE' for each year\n",
    "    cout_stats['RMSE'] = rmse_values1\n",
    "    \n",
    "    # Initialize an empty list to store NSE values\n",
    "    nse_values1= []\n",
    "\n",
    "    # Iterate over unique years in the index\n",
    "    for year in sim_cout_filtered.index.year.unique():\n",
    "        # Filter the data for the current year\n",
    "        year_data = sim_cout_filtered[sim_cout_filtered.index.year == year]\n",
    "        # Calculate the mean of observed flow for the current year\n",
    "        mean_observed1 = year_data['cout'].mean()\n",
    "        # Calculate the numerator of the Nash-Sutcliffe Efficiency (NSE)\n",
    "        numerator1 = np.sum((year_data['cout'] - year_data['ESP Mean Total Flow (cms)'])**2)\n",
    "        # Calculate the denominator of the Nash-Sutcliffe Efficiency (NSE)\n",
    "        denominator1 = np.sum((year_data['cout'] - mean_observed1)**2)\n",
    "        # Calculate NSE for the current year\n",
    "        nse1 = 1 - (numerator1 / denominator1)\n",
    "        # Append the NSE value to the list\n",
    "        nse_values1.append(nse1)\n",
    "\n",
    "    # Create a DataFrame called 'statistics' with 'NSE' for each year\n",
    "    cout_stats['NSE'] = nse_values1\n",
    "    \n",
    "    if swe_rank is not None:\n",
    "        # Read CSV into a DataFrame\n",
    "        swe_rank_df = pd.read_csv(swe_rank, index_col=0)\n",
    "\n",
    "        # Merge 'SWE_Rank' column onto 'statistics' based on indexes\n",
    "        cout_stats= pd.merge(cout_stats, swe_rank_df['SWE_Rank'], left_index=True, right_index=True)\n",
    "\n",
    "        # Move 'SWE_Rank' column to the first position\n",
    "        cout_stats.insert(0, 'SWE_Rank', cout_stats.pop('SWE_Rank'))\n",
    "        \n",
    "    \n",
    "    # define output file\n",
    "    cout_statistics_filename= 'simulated_esp_stats.csv'\n",
    "    cout_stats_output_path = output_directory + cout_statistics_filename\n",
    "    \n",
    "    # Round all values to two decimal places\n",
    "    cout_stats = cout_stats.round(2)\n",
    "    \n",
    "    # Save bias to CSV\n",
    "    cout_stats.to_csv(cout_stats_output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae53841-ef7f-4e3e-8a1d-260769ae9bc4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd512e4c-a92d-4e81-b3d7-3c21d107a6b4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define output file\n",
    "statistics_filename= 'esp_stats.csv'\n",
    "stats_output_path = output_directory + statistics_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61466ca6-f7fa-4574-982f-8360b204b85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all values in DataFrames to floats\n",
    "#statistics = results.astype(float)\n",
    "\n",
    "# Round all values to two decimal places\n",
    "statistics = statistics.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd3b574d-9218-44b9-971d-2beb64a864c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save bias to CSV\n",
    "statistics.to_csv(stats_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718b4f1c-fe5a-4228-afc8-047f1843b920",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
