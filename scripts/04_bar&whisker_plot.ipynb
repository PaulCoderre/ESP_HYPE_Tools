{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86524342-5b41-4d54-91da-9a27b2a7ea18",
   "metadata": {},
   "source": [
    "## Description\n",
    "_______\n",
    "\n",
    "This script generates a bar and whiskers plot for every ESP output found in the directory_path folder.  \n",
    "The plot includes observed streamflow and optionally, simulated streamflow from a full model run.  \n",
    "Plot will be generated for date between start_date and end_date so that performance of different forecast  \n",
    "lead times can be analyzed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf97ce5-fc5b-4c22-bc33-0842746b8670",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01abbe77-9fb8-4d20-adda-3bc7b5e62816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2c2823-9507-493b-b26a-e066b83b6858",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74789fc1-c98d-408e-b683-cb04ed23fc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define inputs for the plot\n",
    "directory_path= '../58213_esp_results/' # directory containing ESP outputs\n",
    "start_date= '04-01'       # start date for esp analysis in %Y-%m-%d\n",
    "end_date= '04-30'         # end date for esp analysis in %Y-%m-%d\n",
    "output_directory= '../'   # directory for outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56debf92-7eb3-450c-b4cb-126fa9d2345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding computed runoff for given year (optional, replace with False if not using)\n",
    "computed_path= '../0058213.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486a55e1-0924-4e18-9565-51631a333d50",
   "metadata": {},
   "source": [
    "### Generate Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4434a601-9d8e-472e-ab63-8882f562353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract month and day from the dates\n",
    "start_month, start_day = start_date.split('-')\n",
    "end_month, end_day = end_date.split('-')\n",
    "\n",
    "# Convert dates to integers\n",
    "start_month, start_day = int(start_month), int(start_day)\n",
    "end_month, end_day = int(end_month), int(end_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdc2779-5476-43ed-b75a-4e32c2937872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the total simulated runoff for each ensemble member\n",
    "all_sum_cout_series = []\n",
    "\n",
    "# Initialize an empty list to store the total observed runoff for each ensemble member\n",
    "all_sum_rout_series = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6967058a-d546-4a29-9a29-a8dc1ead735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if computed_path is not None:\n",
    "    # Read the DataFrame from the computed_path\n",
    "    sim = pd.read_csv(computed_path, sep='\\t', index_col=0)\n",
    "\n",
    "    sim = sim.drop('UNITS', axis=0)\n",
    "\n",
    "    # Convert index to datetime format\n",
    "    sim.index = pd.to_datetime(sim.index, errors='coerce')\n",
    "    \n",
    "    sum_model_sim= []\n",
    "    \n",
    "        # Convert 'cout' column to numeric if needed\n",
    "    sim['cout'] = pd.to_numeric(sim['cout'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29a4819-611e-4001-b9ae-ade2088b49ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each .nc file in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.nc'):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        \n",
    "        # Open the esp output file\n",
    "        esp = xr.open_dataset(file_path)\n",
    "        \n",
    "        # Convert all data variable values to float\n",
    "        esp = esp.astype(float)\n",
    "        \n",
    "        # Convert 'DATE' coordinate to datetime format\n",
    "        esp['DATE'] = pd.to_datetime(esp['DATE'])\n",
    "        \n",
    "        # Extract the year from the last DATE\n",
    "        last_date_year = pd.to_datetime(esp['DATE'][-1].values).year\n",
    "        \n",
    "        # Create start_date and end_date for the analysis period\n",
    "        start_date = pd.Timestamp(year=last_date_year, month=start_month, day=start_day)\n",
    "        end_date = pd.Timestamp(year=last_date_year, month=end_month, day=end_day)\n",
    "        \n",
    "        # Select data between start_date and end_date \n",
    "        ds_selected = esp.sel(DATE=slice(start_date, end_date))\n",
    "        \n",
    "        # Sum 'cout' variable for each ensemble member\n",
    "        sum_cout = ds_selected['cout'].sum(dim='DATE')\n",
    "        sum_rout= ds_selected['rout'].sum(dim='DATE')\n",
    "        \n",
    "        # Convert sum_cout to pandas Series\n",
    "        sum_cout_series = sum_cout.to_series()\n",
    "        sum_rout_series = sum_rout.to_series()\n",
    "        \n",
    "        # Ensure the simulated index is a DatetimeIndex and add year of analysis to series\n",
    "        sum_cout_series.index = pd.to_datetime(sum_cout_series.index)\n",
    "        sum_cout_series.index = sum_cout_series.index.map(lambda x: x.replace(year=last_date_year))\n",
    "        \n",
    "        # Ensure the observed index is a DatetimeIndex and add year of analysis to series\n",
    "        sum_rout_series.index = pd.to_datetime(sum_rout_series.index)\n",
    "        sum_rout_series.index = sum_rout_series.index.map(lambda x: x.replace(year=last_date_year))\n",
    "        \n",
    "        if computed_path is not None:\n",
    "            # Trim the DataFrame based on the date range\n",
    "            model_sim = sim.loc[start_date:end_date]\n",
    "            \n",
    "            # Sum the 'cout' column\n",
    "            sum_sim = model_sim['cout'].sum()\n",
    "            \n",
    "            sim_series= sum_rout_series.copy()\n",
    "            \n",
    "            sim_series[:]= sum_sim\n",
    "            \n",
    "            sim_series.name = 'sim'\n",
    "            \n",
    "            sum_model_sim.append(sim_series)\n",
    "        \n",
    "        # Append the simulated and observed series to the list\n",
    "        all_sum_cout_series.append(sum_cout_series)\n",
    "        all_sum_rout_series.append(sum_rout_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab83d936-ac3b-4672-9064-3d65f7d6d4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all sum_cout_series into a single series\n",
    "sum_cout_series_combined = pd.concat(all_sum_cout_series)\n",
    "sum_rout_series_combined = pd.concat(all_sum_rout_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cb5589-da20-4f84-81b0-66a53fd5a2d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract simulated data for each unique year \n",
    "data = [sum_cout_series_combined[sum_cout_series_combined.index.year == year].values \n",
    "        for year in sum_cout_series_combined.index.year.unique()]\n",
    "\n",
    "# Initialize plot size\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Create boxplot of simulated flow with modified box properties\n",
    "box = plt.boxplot(data, labels=sum_cout_series_combined.index.year.unique(), patch_artist=True, \n",
    "                  medianprops=dict(color='red'), boxprops=dict(color='black', facecolor='lightgray'))\n",
    "\n",
    "# Set plot title and labels\n",
    "plt.title('Boxplot of Total ESP Streamflow with Total Observed Streamflow for Analysis Period')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel(f'Total Streamflow Between {start_month}-{start_day} and {end_month}-{end_day} (cms)')\n",
    "\n",
    "# Extract and plot scatter data for observed flow\n",
    "for i, year in enumerate(sum_cout_series_combined.index.year.unique(), start=1):\n",
    "    y = sum_rout_series_combined[sum_rout_series_combined.index.year == year].values\n",
    "    # Add some random \"jitter\" to the x-axis\n",
    "    x = np.random.normal(i, 0.0000001, size=len(y))  # plot all dots together\n",
    "    plt.plot(x, y, 'r.', alpha=0.2, markersize=15, label='Observed' if i == 1 else \"\")\n",
    "\n",
    "# Add legend\n",
    "legend_labels = ['Median', 'Q1 to Q3', 'Min/Max', 'Outliers', 'Observed']\n",
    "legend_colors = ['red', 'grey', 'black', 'black', 'red']    \n",
    "    \n",
    "if computed_path is not None:\n",
    "    sum_model_sim_combined= pd.concat(sum_model_sim)\n",
    "    # Plot actual model simulated flow\n",
    "    for i, year in enumerate(sum_cout_series_combined.index.year.unique(), start=1):\n",
    "        y = sum_model_sim_combined[sum_model_sim_combined.index.year == year].values\n",
    "        # Add some random \"jitter\" to the x-axis\n",
    "        x = np.random.normal(i, 0.00001, size=len(y))  # plot all dots together\n",
    "        plt.plot(x, y, 'g.', alpha=0.2, markersize=15, label='Simulated' if i == 1 else \"\")\n",
    "        \n",
    "    # Update legend \n",
    "    legend_labels = ['Median', 'Q1 to Q3', 'Min/Max', 'Outliers', 'Observed', 'Simulated']\n",
    "    legend_colors = ['red', 'grey', 'black', 'black', 'red', 'green']\n",
    "\n",
    "# Create legend patches\n",
    "legend_patches = [\n",
    "    plt.Line2D([0], [0], color=color, linewidth=3, label=label) if label == 'Median' or label == 'Whiskers (Min/Max)'\n",
    "    else plt.Line2D([0], [0], marker='o', color='w', label=label, \n",
    "                    markerfacecolor=color, markersize=10) if label == 'Observed' or label == 'Simulated'\n",
    "    else plt.Line2D([0], [0], marker='s', color='w', label=label, \n",
    "                    markerfacecolor=color, markersize=10)  # Square marker for 'Q1 to Q3'\n",
    "    if label != 'Outliers'\n",
    "    else plt.Line2D([0], [0], marker='o', color='w', label=label, \n",
    "                    markerfacecolor='none', markersize=10, markeredgecolor='black')  # Clear circle for 'Outliers'\n",
    "    for label, color in zip(legend_labels, legend_colors)\n",
    "]\n",
    "\n",
    "\n",
    "# Add legend to plot\n",
    "plt.legend(handles=legend_patches, loc='upper right')\n",
    "\n",
    "# Save the plot to the specified directory\n",
    "save_path = os.path.join(output_directory, 'boxplot.png')\n",
    "plt.savefig(save_path)\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8402b75-50e5-4c24-92a5-3c87497925d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
