{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35d139ef-270e-4d92-9a46-036cfb163bfb",
   "metadata": {},
   "source": [
    "## Description\n",
    "_______\n",
    "\n",
    "This script calculates statistics for the esp simulated vs. historical simulated streamflow from the ESP outputs. This alows for a hindcast to be compared to simulated data to avoid skewing the results from model error. Statistics currently being calculated are bias for each year included in the ESP analysis, correlation coefficient and RMSE and (Huang et al. 2017). These statistics are being calculated with the mean of the ensemble. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516a2092-0036-482a-9828-7dad5224593e",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01abbe77-9fb8-4d20-adda-3bc7b5e62816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.integrate import simps\n",
    "from properscoring import crps_ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2c2823-9507-493b-b26a-e066b83b6858",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74789fc1-c98d-408e-b683-cb04ed23fc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define inputs for the plot\n",
    "directory_path= '../58418_esp_results/' # directory containing ESP outputs\n",
    "start_date= '04-01'       # start date for esp analysis in %Y-%m-%d\n",
    "end_date= '07-31'         # end date for esp analysis in %Y-%m-%d\n",
    "output_directory= '../simulated_stats/'   # location for the outputs\n",
    "computed_path='../0058418.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ed2b7a-d10a-4cd2-8396-df03455b3fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding swe rank\n",
    "swe_rank= None #'../swe_analysis/swerank.csv' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486a55e1-0924-4e18-9565-51631a333d50",
   "metadata": {},
   "source": [
    "### Generate Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4434a601-9d8e-472e-ab63-8882f562353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract month and day from the dates\n",
    "start_month, start_day = start_date.split('-')\n",
    "end_month, end_day = end_date.split('-')\n",
    "\n",
    "# Convert dates to integers\n",
    "start_month, start_day = int(start_month), int(start_day)\n",
    "end_month, end_day = int(end_month), int(end_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdc2779-5476-43ed-b75a-4e32c2937872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the total simulated runoff for each ensemble member\n",
    "all_sum_cout_series = []\n",
    "\n",
    "# Initialize an empty list to store the total observed runoff for each ensemble member\n",
    "all_sum_rout_series = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6cb1ec-7c56-41b8-bc72-b57a2e1fd6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the DataFrame from the computed_path\n",
    "sim = pd.read_csv(computed_path, sep='\\t', index_col=0)\n",
    "\n",
    "sim = sim.drop('UNITS', axis=0)\n",
    "\n",
    "# Convert index to datetime format\n",
    "sim.index = pd.to_datetime(sim.index, errors='coerce')\n",
    "\n",
    "# Convert 'cout' column to numeric if needed\n",
    "sim['cout'] = pd.to_numeric(sim['cout'], errors='coerce')\n",
    "\n",
    "# Extract unique years from the index of sim\n",
    "unique_years = sim.index.year.unique()\n",
    "\n",
    "# Initialize an empty list to store trimmed DataFrames\n",
    "trimmed_dfs = []\n",
    "\n",
    "# Loop through each unique year\n",
    "for year in unique_years:\n",
    "    # Trim the DataFrame to keep only data within the specified start and end dates for each year\n",
    "    year_start_date = '{}-{}'.format(year, start_date)\n",
    "    year_end_date = '{}-{}'.format(year, end_date)\n",
    "    trimmed_df = sim.loc[year_start_date:year_end_date]\n",
    "    trimmed_dfs.append(trimmed_df)\n",
    "\n",
    "# Concatenate the trimmed DataFrames into a single DataFrame\n",
    "sim_trimmed = pd.concat(trimmed_dfs)\n",
    "\n",
    "# Drop all columns except for 'cout'\n",
    "sim_cout = sim_trimmed[['cout']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29a4819-611e-4001-b9ae-ade2088b49ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each .nc file in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.nc'):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        \n",
    "        # Open the esp output file\n",
    "        esp = xr.open_dataset(file_path)\n",
    "        \n",
    "        # Convert all data variable values to float\n",
    "        esp = esp.astype(float)\n",
    "        \n",
    "        # Convert 'DATE' coordinate to datetime format\n",
    "        esp['DATE'] = pd.to_datetime(esp['DATE'])\n",
    "        \n",
    "        # Extract the year from the last DATE\n",
    "        last_date_year = pd.to_datetime(esp['DATE'][-1].values).year\n",
    "        \n",
    "        # Create start_date and end_date for the analysis period\n",
    "        start_date = pd.Timestamp(year=last_date_year, month=start_month, day=start_day)\n",
    "        end_date = pd.Timestamp(year=last_date_year, month=end_month, day=end_day)\n",
    "        \n",
    "        # Select data between start_date and end_date \n",
    "        ds_selected = esp.sel(DATE=slice(start_date, end_date))\n",
    "        \n",
    "        # Sum 'cout' variable for each ensemble member\n",
    "        sum_cout = ds_selected['cout'].mean(dim='ensemble_member') # change to .median for median stats\n",
    "        \n",
    "        # Convert sum_cout to pandas Series\n",
    "        sum_cout_series = sum_cout.to_series()\n",
    "        \n",
    "        # Ensure the simulated index is a DatetimeIndex and add year of analysis to series\n",
    "        sum_cout_series.index = pd.to_datetime(sum_cout_series.index)\n",
    "        sum_cout_series.index = sum_cout_series.index.map(lambda x: x.replace(year=last_date_year))\n",
    "        \n",
    "        # Append the simulated and observed series to the list\n",
    "        all_sum_cout_series.append(sum_cout_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab83d936-ac3b-4672-9064-3d65f7d6d4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all sum_cout_series into a single series\n",
    "sum_cout_series_combined = pd.concat(all_sum_cout_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1172200-69ef-47b1-8c12-d205e0ee12c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique years from the index of sum_cout_series_combined\n",
    "unique_years_sum = sum_cout_series_combined.index.year.unique()\n",
    "\n",
    "# Filter sim_cout to include only the years found in sum_cout_series_combined\n",
    "sim_cout_filtered = sim_cout[sim_cout.index.year.isin(unique_years_sum)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8402b75-50e5-4c24-92a5-3c87497925d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results dataframe\n",
    "results = pd.DataFrame({\n",
    "    'ESP Mean Total Flow (cms)': sum_cout_series_combined,\n",
    "    'Simulated Total Flow (cms)': sim_cout_filtered['cout']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc3fcfa-0e5e-41ba-8209-4d0131878a38",
   "metadata": {},
   "source": [
    "#### Calculate Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98dc167-e7e7-412e-97a1-bc29a78b02c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'results' is your DataFrame\n",
    "results[results < 0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1918173-bc69-458a-8860-61672919a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the bias for each day\n",
    "results['Bias'] = results['ESP Mean Total Flow (cms)'] - results['Simulated Total Flow (cms)']\n",
    "\n",
    "# Group by year and calculate the mean bias for each year\n",
    "mean_bias_by_year = results.groupby(results.index.year)['Bias'].mean()\n",
    "\n",
    "# Group by year and calculate the mean bias for each year\n",
    "mean_obs_year = results.groupby(results.index.year)['Simulated Total Flow (cms)'].mean()\n",
    "\n",
    "normalized_percent_bias= (mean_bias_by_year/mean_obs_year) *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1035e04e-4278-4e43-b302-26abd2412cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame called 'statistics' from the Series with index defined\n",
    "statistics = pd.DataFrame(columns=['Mean Bias (cms)'], index=mean_bias_by_year.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a11d84-cd03-46d3-89ec-0397481e04f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the 'Mean Percent Bias' column with the values from 'mean_percent_bias_by_year'\n",
    "statistics['Mean Bias (cms)'] = mean_bias_by_year.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a06835b-ac58-4f10-9e76-c1dd33381a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics['Mean Normalized Percent Bias (cms)'] = normalized_percent_bias.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f01738-a6aa-43bd-988b-25dd54ab1d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store correlation coefficients\n",
    "correlation_coefficients = []\n",
    "\n",
    "# Iterate over unique years in the index\n",
    "for year in results.index.year.unique():\n",
    "    # Filter the data for the current year\n",
    "    year_data = results[results.index.year == year]\n",
    "    # Calculate the correlation coefficient for the current year\n",
    "    correlation_coefficient = np.corrcoef(year_data['ESP Mean Total Flow (cms)'], year_data['Simulated Total Flow (cms)'])[0, 1]\n",
    "    # Append the correlation coefficient to the list\n",
    "    correlation_coefficients.append(correlation_coefficient)\n",
    "\n",
    "statistics['Correlation Coefficient'] = correlation_coefficients\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8c5810-1b3e-4e68-b994-65079e76a0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store RMSE values\n",
    "rmse_values = []\n",
    "mean_flows = []\n",
    "\n",
    "# Iterate over unique years in the index\n",
    "for year in results.index.year.unique():\n",
    "    # Filter the data for the current year\n",
    "    year_data = results[results.index.year == year]\n",
    "    # Calculate RMSE for the current year\n",
    "    rmse = np.sqrt(np.mean((year_data['Simulated Total Flow (cms)'] - year_data['ESP Mean Total Flow (cms)'])**2))\n",
    "    # Append the RMSE value to the list\n",
    "    rmse_values.append(rmse)\n",
    "    # find mean observed flow\n",
    "    obs_mean= np.mean(year_data['Simulated Total Flow (cms)'])\n",
    "    # append mean flows to list                  \n",
    "    mean_flows.append(obs_mean)\n",
    "    \n",
    "    \n",
    "# Create a DataFrame called 'statistics' with 'RMSE' for each year\n",
    "statistics['RMSE'] = rmse_values\n",
    "statistics['NRMSE']= mean_flows\n",
    "statistics['NRMSE']= statistics['RMSE'] / statistics['NRMSE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346b64aa-7ff3-4bad-b207-c5584d41dc95",
   "metadata": {},
   "source": [
    "SWE Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe3a0c3-781e-4d5e-8536-57e632be336b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if swe_rank is not None:\n",
    "    # Read CSV into a DataFrame\n",
    "    swe_rank_df = pd.read_csv(swe_rank, index_col=0)\n",
    "    \n",
    "    # Merge 'SWE_Rank' column onto 'statistics' based on indexes\n",
    "    statistics= pd.merge(statistics, swe_rank_df['SWE_Rank'], left_index=True, right_index=True)\n",
    "    \n",
    "    \n",
    "    # Move 'SWE_Rank' column to the first position\n",
    "    statistics.insert(0, 'SWE_Rank', statistics.pop('SWE_Rank'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae53841-ef7f-4e3e-8a1d-260769ae9bc4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd512e4c-a92d-4e81-b3d7-3c21d107a6b4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define output file\n",
    "statistics_filename= 'mean_milk_simulated_esp_stats.csv'\n",
    "stats_output_path = output_directory + statistics_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61466ca6-f7fa-4574-982f-8360b204b85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all values in DataFrames to floats\n",
    "#statistics = results.astype(float)\n",
    "\n",
    "# Round all values to two decimal places\n",
    "statistics = statistics.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3b574d-9218-44b9-971d-2beb64a864c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save bias to CSV\n",
    "statistics.to_csv(stats_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d5f854-9b8f-4242-b2e4-e31cd25ee158",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
